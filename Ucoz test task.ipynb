{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формулировка задачи:\n",
    "\n",
    "Необходимо создать консольную (работающую из командной строки) утилиту. Программа спрашивает домен и забирает с введённого адреса файл robots.txt. Затем скрипт парсит файл и выводит его содержимое в виде объекта. Ключами объекта являются параметры User-Agent, а значениями — вложенный объект. Вложенный объект содержит два поля Allow и Dissallow, каждый из которых является массивом соответствующих URL из robots.txt. Код выложить на GitHub\n",
    "Пример:\n",
    "\n",
    "{\n",
    "  \"*\": {\n",
    "      \"Disallow\": [\"/cgi-bin\"],\n",
    "      \"Allow\": [\"/\"]\n",
    "   },\n",
    "  \"GoogleBot\": {\n",
    "      \"Disallow\": [\"/cgi-bin\"],\n",
    "      \"Allow\": [\"/\"]\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декомпозиция задачи:\n",
    "1. У нас консольная программа, но передавать параметры при запуске вроде бы не нужно. Есть слово \"скрипт\", но нет ограничения на язык. Пусть будет python, его (при прочих равных) приятно читать и видеть. Системой пусть будет linux, но ничего платформоспецифичного вроде бы не предполагается.\n",
    "\n",
    "2. Нужно спросить о домене и забрать с введённого адреса. Предполагаю, что \"домен\" и \"адрес\" здесь понимаются как синонимы, а не как \"домен + адрес\" или как-то ещё. Есть два способа это сделать - написать текстом строку и вбить IP-адрес. Можно поставить проверки на основе регулярных выражений, которые покажут, является ли введённый текст чем-то осмысленным. Ещё можно ругаться, если нет такого адреса, но для этого вроде бы есть готовая ругалка\n",
    "\n",
    "3. Нужно вытащить файл и прочитать. Возможные проблемы: по адресу нет файла, нет нужной структуры внутри.\n",
    "\n",
    "4. Чтобы вернуть что нужно, можно было бы определить пользовательский объект. Но вид объекта наводит на мысль либо о словаре словарей, который уже реализован. Воспользуемся им.\n",
    "\n",
    "5. В требованиях есть слово \"выводит содержимое в виде объекта\". По некоторому размышлению, предполагает, что мы, возможно, хотим уметь сериализовать (или хотя бы выводить на печать) полученный объект, чтобы прямо в консоли видеть результат. С этим тоже нет проблемы, но для красивого вывода можно пробежаться по ключам, чтобы не смотреть совсем уж на мешанину.\n",
    "\n",
    "Методы:\n",
    "\n",
    "1. Получить url\n",
    "2. Соединиться\n",
    "3. Распарсить\n",
    "4. Прибраться за собой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Замечу, что на stackoverflow <a href = https://stackoverflow.com/questions/43085744/parsing-robots-txt-in-python#43086135> есть </a> наводящее на нужные мысли (правда, для python 2) решение такого вот вида:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Allowed': ['/wp-admin/admin-ajax.php'], 'Disallowed': ['/wp-admin/', '/search/', '/wp-login.php', '/activate/', '/cgi-bin/', '/mshots/v1/', '/next/', '/public.api/']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "result = os.popen(\"curl https://fortune.com/robots.txt\").read()\n",
    "result_data_set = {\"Disallowed\":[], \"Allowed\":[]}\n",
    "\n",
    "for line in result.split(\"\\n\"):\n",
    "    if line.startswith('Allow'):    # this is for allowed url\n",
    "        result_data_set[\"Allowed\"].append(line.split(': ')[1].split(' ')[0])    # to neglect the comments or other junk info\n",
    "    elif line.startswith('Disallow'):    # this is for disallowed url\n",
    "        result_data_set[\"Disallowed\"].append(line.split(': ')[1].split(' ')[0])    # to neglect the comments or other junk info\n",
    "\n",
    "print (result_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, оно не учитывает наличие нескольких user-agent.\n",
    "\n",
    "Дополним его и избавим от указанных проблем, попутно придав формат тестового задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def is_string_a_valid_url(string):\n",
    "    \"\"\"\n",
    "    This function add some validation for our user input. This one is for the case when we expect a url to be entered.\n",
    "    The idea of the regular expression is from here: https://web.izjum.com/regexp-email-url-phone (in Russian)\n",
    "    :param string: a string we want to check\n",
    "    :return: True or False\n",
    "    \"\"\"\n",
    "    url_regexp = '^((https?|ftp)\\:\\/\\/)?([a-z0-9]{1})((\\.[a-z0-9-])|([a-z0-9-]))*\\.([a-z]{2,6})(\\/?)$'\n",
    "    if re.match(url_regexp, string):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def ask_for_url():\n",
    "    \"\"\"\n",
    "    The first requirement for this was to read a user's input.\n",
    "    Using previously defined functions, namely: is_string_a_valid_url() and is_string_a_valid_ip()\n",
    "    we are going to make a simple sanity check.\n",
    "\n",
    "    It also seems convenient to automatically add an 'https://' prefix if there is no protocol specified.\n",
    "    and add '/robots.txt'\n",
    "\n",
    "    :return: a url if everything went well. Returns 1 in case of errors.\n",
    "    \"\"\"\n",
    "    url_entered = input(\"Enter the url you wich to retrieve 'robots.txt' from: \")\n",
    "\n",
    "    if not url_entered.startswith('http') and not url_entered[0].isdigit():\n",
    "        url_entered = \"https://\" + url_entered\n",
    "\n",
    "    if is_string_a_valid_url(url_entered) and not url_entered.endswith('/robots.txt'):\n",
    "        url_entered += '/robots.txt'\n",
    "        return url_entered\n",
    "    else:\n",
    "        print(\"You're probably entering not a valid url. Please make sure the input is correct.\")\n",
    "        return 1\n",
    "\n",
    "\n",
    "def download_robots_txt(path_to_robots_txt, my_user_agent='*'):\n",
    "    \"\"\"\n",
    "    This method uses the 'request' package to retrieve a file from the url specified.\n",
    "    An optional parameter is for the (unlikely) case where we need a specific user-agent to be able to download\n",
    "    a file we want.\n",
    "\n",
    "    It uses a procedure that iterates over a file we download (for almost impossible case of robots.txt\n",
    "    being exceptionally large).\n",
    "\n",
    "    Prints out the logstring and the filename, just for convenience\n",
    "\n",
    "    :param path_to_robots_txt: a full path to robots.txt.\n",
    "    :param my_user_agent: in case we need to specify one\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    local_filename = \"robots_local_temp.txt\"\n",
    "    my_headers = requests.utils.default_headers()\n",
    "    my_headers.update({'User-Agent': my_user_agent})\n",
    "    try:\n",
    "        r = requests.get(path_to_robots_txt, headers=my_headers)\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                if chunk:  # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "        logstring = 'download finished, temporary file ./' + local_filename + ' created'\n",
    "        print(logstring)\n",
    "        return 0\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def parse_robots_txt():\n",
    "    \"\"\"\n",
    "    Parses a local copy of the file 'robots.txt' we probably have.\n",
    "\n",
    "    To pass a file only once, we needed a logic that allows to store the very first user-agent name as a key,\n",
    "    and associate the collected data with it only after we have met the next one (or the end of file).\n",
    "\n",
    "    :return: a resulting data structure which is essentially a dictionary of dictionaries. The external keys are\n",
    "    User-Agents, the internal ones are 'Allowed' and 'Disallowed'. The internal values are lists of domains\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"robots_local_temp.txt\"):\n",
    "        local_file = open('robots_local_temp.txt', 'r')\n",
    "        resulting_data_set = {}\n",
    "        agent_name_current = 'NoAgent'\n",
    "        agent_name_next = 'NoAgent'\n",
    "        for line in local_file:\n",
    "            line = line.split('\\n')[0]\n",
    "            if line.startswith('User-agent'):\n",
    "                agent_name_next = line.split(': ')[1].split(' ')[0]\n",
    "                if not agent_name_current == 'NoAgent':\n",
    "                    resulting_data_set[agent_name_current] = data_set_for_current_user_agent\n",
    "                agent_name_current = agent_name_next\n",
    "                data_set_for_current_user_agent = {\"Disallowed\": [], \"Allowed\": []}\n",
    "            else:\n",
    "                if line.startswith('Allow'):\n",
    "                    # filter some possibly useless info and comments\n",
    "                    data_set_for_current_user_agent[\"Allowed\"].append(line.split(': ')[1].split(' ')[0])\n",
    "                elif line.startswith('Disallow'):\n",
    "                    # same thing here\n",
    "                    data_set_for_current_user_agent[\"Disallowed\"].append(line.split(': ')[1].split(' ')[0])\n",
    "        # we now have the info of the last (and probably the unique one) agent. So it is time to write them to a\n",
    "        # data structure we have and stop.\n",
    "        agent_name_current = agent_name_next\n",
    "        resulting_data_set[agent_name_current] = data_set_for_current_user_agent\n",
    "        return resulting_data_set\n",
    "    else:\n",
    "        print('A local copy of robots.txt is missing for some reason.')\n",
    "        return 1\n",
    "\n",
    "\n",
    "def print_out_the_result(result):\n",
    "    \"\"\"\n",
    "    This function is to generate a bit more human-readable form of the output.\n",
    "    Makes a bit easier to track which 'Allows' and 'Disallows' suits a User-Agent we are interested in.\n",
    "    :param: a data structure returned by parse_robots_txt() method\n",
    "    :return: 0 - for and ideal case. 1 - if we have no output but somehow reached this point and launched a function\n",
    "    \"\"\"\n",
    "    if result == 1:\n",
    "        print(\"No output created\")\n",
    "        return 1\n",
    "    else:\n",
    "        for key in result.keys():\n",
    "            print(key, ':')\n",
    "            for inner_key in result[key]:\n",
    "                print(inner_key, ':')\n",
    "                print(result[key][inner_key])\n",
    "            print()\n",
    "        return 0\n",
    "\n",
    "\n",
    "def dispose_of_temp_file():\n",
    "    \"\"\"\n",
    "    One way to parse a file is to download it and store its local version.\n",
    "    However, it is quite awkward to leave a user with a file he didn't want to create.\n",
    "    Or use a file with the same name someone occasionally left there for some reason.\n",
    "    So, before and after we run our code, we need to clean up.\n",
    "\n",
    "    :return: 0 - if we can remove a file. Raises a warning otherwise.\n",
    "    \"\"\"\n",
    "    if os.path.exists(\"robots_local_temp.txt\"):\n",
    "        try:\n",
    "            os.remove(\"robots_local_temp.txt\")\n",
    "            print('cleaning up...')\n",
    "        except OSError:\n",
    "            raise UserWarning(\"Cannot remove 'robots_local_temp.txt'. Is it opened somewhere?\")\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning up...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispose_of_temp_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the url you wich to retrieve 'robots.txt' from: habrahabr.ru\n",
      "https://habrahabr.ru/robots.txt\n"
     ]
    }
   ],
   "source": [
    "url = ask_for_url()\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download finished, temporary file ./robots_local_temp.txt created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_robots_txt(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Yandex': {'Allowed': [], 'Disallowed': ['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']}, '*': {'Allowed': [], 'Disallowed': ['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']}, 'Slurp': {'Allowed': [], 'Disallowed': ['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']}, 'Googlebot': {'Allowed': [], 'Disallowed': ['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']}}\n"
     ]
    }
   ],
   "source": [
    "result_obtained = parse_robots_txt()\n",
    "print_out_the_result(result_obtained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yandex :\n",
      "Allowed :\n",
      "[]\n",
      "Disallowed :\n",
      "['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']\n",
      "\n",
      "* :\n",
      "Allowed :\n",
      "[]\n",
      "Disallowed :\n",
      "['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']\n",
      "\n",
      "Slurp :\n",
      "Allowed :\n",
      "[]\n",
      "Disallowed :\n",
      "['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']\n",
      "\n",
      "Googlebot :\n",
      "Allowed :\n",
      "[]\n",
      "Disallowed :\n",
      "['/search/', '/js/', '/css/', '/ajax/', '/login/', '/register/', '/*utm_']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispose_of_temp_file()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}